# Jupyter-Data-manipulation
Using python libraries to clean and process the data
#Step1
import pandas as pd
import numpy as np
f = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")
f_short = f.iloc[6676:6895]
f_short["ID-Name"].unique()
array([u"v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6678-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6679-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6680-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6681-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6682-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6683-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6684-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6685-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6686-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6687-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6688-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6689-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6690-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6691-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6692-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6693-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6695-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6696-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6697-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6698-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6699-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6700-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6701-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6702-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6703-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6704-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6705-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6706-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6707-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6708-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6709-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6710-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6711-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6712-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6713-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6714-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6715-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6716-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6717-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6718-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6719-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6720-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6721-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6722-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6723-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6724-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6725-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6726-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6727-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6729-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6730-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6731-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6732-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6733-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6734-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6735-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6736-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6737-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6738-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6739-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6740-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6741-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6742-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6743-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6744-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6746-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6747-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6748-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6749-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6750-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6751-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6752-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6753-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6754-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6755-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6756-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6757-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6758-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6759-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6760-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6761-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6763-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6764-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6765-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6766-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6767-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6768-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6769-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6770-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6771-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6772-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6773-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6774-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6775-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6776-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6777-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6778-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u"v6779-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
       u'v6780-PAY ANYTHING FOR ELCTRNC PROD I WANT',
       u'v6781-I LIKE INFO ABT ELCTRNC ITEM BEFORE BUY',
       u'v6782-I SHOP FOR BEST DEAL IN ELCTRNC EQUIP',
       u'v6783-FRIENDS ASK MY ADVICE BUY ELCTRNC EQUIP',
       u'v6784-CMPTRS CONFUSE ME,NEVER GET USED TO THEM',
       u"v6785-I ASK FRIENDS' ADVICE BEFOR BUY ELCTRNCS",
       u'v6786-LIKE TO LEARN ABOUT COMPUTER TECH/WEB',
       u'v6787-I TRY KEEP UP/DEVELOPMENTS IN TECHNOLOGY',
       u'v6788-LOVE TO BUY NEW GADGETS AND APPLIANCES',
       u'v6789-MY COMPUTER IS A PRIMARY SOURCE OF FUN',
       u'v6790-PEOPLE ASK MY OPINION/BUYING NEW TCHNLGY',
       u'v6791-BUY TECHNOLOGY/CONNECTS TO PRODS I HAVE',
       u'v6792-ABLE TO MANAGE W/O MANY TECHNOLOGY PRODS',
       u'v6793-I LIKE TO HAVE A LOT OF GADGETS',
       u"v6794-TECHNOLOGY IS MOVING FAST/DON'T KEEP UP",
       u'v6795-WTCHNG RCRD CNTNT/IN-HOME NETWRK/BENEFIT',
       u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6797-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6798-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6799-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6800-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6801-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6802-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6803-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6805-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6806-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6807-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6808-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6809-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6810-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6811-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6812-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6813-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6814-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6815-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6816-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6817-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6818-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6819-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6821-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6822-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6823-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6824-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6825-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6826-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6827-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6829-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6830-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6831-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6832-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6833-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6834-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6835-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6837-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6838-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6839-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6840-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6841-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6842-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6843-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6844-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6845-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6846-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6847-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6848-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6849-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6850-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6851-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6852-USE SRCH ENGINE/FIND INFO ABT ME ONLINE',
       u'v6853-HVE FAIR AMT CTRL OVR INFO ABT ME ONLINE',
       u'v6854-LOOK UP CO/ORG ONLNE BEFORE GVNG MY INFO',
       u'v6855-I OFTEN READ COMPANIES PRIVACY STATEMNTS',
       u'v6856-MOST PRSNL INFO ABOUT ME ONLINE HARMLESS',
       u'v6857-OK IF COS USE MY INFO FOR PRODS/SVCS',
       u'v6858-UNDRSTND RISKS OF PRVDNG PERS INFO ONLNE',
       u'v6859-WILL PROVIDE PERS INFO FOR SMTHNG I WANT',
       u'v6860-PRVDE PRS INFO TO COS W/TRSTD SEAL/APPRV',
       u'v6861-COS CAN SHARE MY PROD PREF IF ANONYMOUS',
       u'v6862-LIKE KNWNG HOW COS ARE USING INFO ABT ME',
       u'v6863-USE INTERNET LESS B/C OF PRVACY CONCERNS',
       u'v6864-PRVDNG PERS INFO OFFLINE/RISKY AS ONLINE',
       u'v6865-WLD PRTCPTE/PRGM ABT MY PRIVACY PREFRNCS',
       u'v6866-WNT MORE PERSL CTRL/INFO COS HAVE ABT ME',
       u'v6867-KNOW PPL W/NEG EXPRNCE/PERS INFO ONLINE',
       u'v6868-I TRST THE FED GOV TO PROTECT MY PRIVACY',
       u'v6869-ONCE PERS INFO ONLNE/CAN DO NTHNG ABT IT',
       u'v6870-HAD NEG EXPERIENCE W/ONLNE INFO ABOUT ME',
       u'v6871-USE SRCH ENGINE/FIND INFO ABT ME ONLINE',
       u'v6872-HVE FAIR AMT CTRL OVR INFO ABT ME ONLINE',
       u'v6873-LOOK UP CO/ORG ONLNE BEFORE GVNG MY INFO',
       u'v6874-I OFTEN READ COMPANIES PRIVACY STATEMNTS',
       u'v6875-MOST PRSNL INFO ABOUT ME ONLINE HARMLESS',
       u'v6876-OK IF COS USE MY INFO FOR PRODS/SVCS',
       u'v6877-UNDRSTND RISKS OF PRVDNG PERS INFO ONLNE',
       u'v6878-WILL PROVIDE PERS INFO FOR SMTHNG I WANT',
       u'v6879-PRVDE PRS INFO TO COS W/TRSTD SEAL/APPRV',
       u'v6880-COS CAN SHARE MY PROD PREF IF ANONYMOUS',
       u'v6881-LIKE KNWNG HOW COS ARE USING INFO ABT ME',
       u'v6882-USE INTERNET LESS B/C OF PRVACY CONCERNS',
       u'v6883-PRVDNG PERS INFO OFFLINE/RISKY AS ONLINE',
       u'v6884-WLD PRTCPTE/PRGM ABT MY PRIVACY PREFRNCS',
       u'v6885-WNT MORE PERSL CTRL/INFO COS HAVE ABT ME',
       u'v6886-KNOW PPL W/NEG EXPRNCE/PERS INFO ONLINE',
       u'v6887-I TRST THE FED GOV TO PROTECT MY PRIVACY',
       u'v6888-ONCE PERS INFO ONLNE/CAN DO NTHNG ABT IT',
       u'v6889-HAD NEG EXPERIENCE W/ONLNE INFO ABOUT ME',
       u'v6890-USE SRCH ENGINE/FIND INFO ABT ME ONLINE',
       u'v6891-HVE FAIR AMT CTRL OVR INFO ABT ME ONLINE',
       u'v6892-LOOK UP CO/ORG ONLNE BEFORE GVNG MY INFO',
       u'v6893-I OFTEN READ COMPANIES PRIVACY STATEMNTS',
       u'v6894-MOST PRSNL INFO ABOUT ME ONLINE HARMLESS',
       u'v6895-OK IF COS USE MY INFO FOR PRODS/SVCS'], dtype=object)
#Step2
import pandas as pd

f = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")

f["Name"] = f["ID-Name"].rename()

widths = f.col_len.tolist()

names = f.Name.tolist()
#We will start with all 7 possible answers:
use_cols = [u"v1-ID",u"v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", u"v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6711-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
            u"v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6779-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
           ]
tx = pd.read_fwf("/home/PLN9630/first1k.txt", widths=widths, names=names, usecols = use_cols)

tx[np.isnan(tx)] = 0
tx.head(10)
v1-ID	v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6711-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	v6779-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP
0	1985951	0.0	0.0	0.0	1.0	0.0	0.0	0.0
1	1985952	0.0	0.0	0.0	1.0	0.0	0.0	0.0
2	1985954	0.0	0.0	0.0	0.0	0.0	1.0	1.0
3	1985955	0.0	0.0	0.0	0.0	0.0	1.0	1.0
4	1985960	0.0	0.0	0.0	0.0	0.0	1.0	1.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	0.0	0.0	0.0	0.0	1.0	1.0
7	1985964	0.0	0.0	0.0	0.0	1.0	0.0	1.0
8	1985966	0.0	0.0	0.0	0.0	1.0	0.0	1.0
9	1985967	0.0	0.0	0.0	0.0	0.0	1.0	1.0
#Step3
tx.shape
#(1000, 8)
#We have a thousand survey partcipants, which means we would expect to see each row to be sum up as one. If it's not equal to 1, 
#it's either was omitted or more than one option has been selected by a respondent.

#Let's rename the column titles to make it easier to understand the table.
txt = tx.rename(columns={u"v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Agree A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
                         u"v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Agree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6711-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Any Agree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Neither Agree Or Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
            u"v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Disagree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Disagre A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6779-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Any Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP"})

#As we may see, keeping such columns as Any Agree or Any Disagree creates a duplication and possible further confusion. 
#One of potential possibilities would be to drop them alltogether and leave the rest. It would be worth considering keeping
#those variables in case when we would observe missed responses. They could have been potentially used a replacement.

#Let's go ahead and create an extra column to tally up the sum values for each row
txt.assign(Sum=tx.select_dtypes(['number']).sum(1) - tx["v1-ID"])
#As we may see, respondents were very attentive: there are no duplicated answers.
v1-ID	Agree A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Agree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Any Agree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Neither Agree Or Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Disagree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Disagre A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Any Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Sum
0	1985951	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
1	1985952	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
2	1985954	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
3	1985955	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
4	1985960	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
7	1985964	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
8	1985966	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
9	1985967	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
10	1985969	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
11	1985970	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
12	1985977	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
13	1985979	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
14	1985980	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
15	1985981	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
16	1985986	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
17	1985987	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
18	1985989	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
19	1985990	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
20	1985992	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
21	1985994	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
22	1985995	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
23	1985997	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
24	1985998	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
25	1986022	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
26	1986023	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
27	1986027	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
28	1986030	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
29	1986031	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
...	...	...	...	...	...	...	...	...	...
970	1990174	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
971	1990187	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
972	1990188	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
973	1990210	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
974	1990211	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
975	1990213	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
976	1990214	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
977	1990234	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
978	1990235	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
979	1990237	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
980	1990238	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
981	1990239	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
982	1990240	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
983	1990245	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
984	1990246	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
985	1990253	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
986	1990258	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
987	1990259	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
988	1990269	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
989	1990275	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
990	1990276	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
991	1990282	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
992	1990308	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
993	1990310	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
994	1990311	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
995	1990318	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
996	1990319	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
997	1990339	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
998	1990341	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
999	1990342	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
1000 rows × 9 columns

#Repeat Step2
#Let's update the dataset by removing "Any Disagree" and "Any Agree" values
f = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")

f["Name"] = f["ID-Name"].rename()


widths = f.col_len.tolist()

names = f.Name.tolist()

use_cols = [u"v1-ID",u"v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", u"v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
            u"v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP"
           ]
# we selcted 5 options for the answer : "Agree A Lot", Agree A Little", "Neither Agree or Disagree", "Disagree A Little", "Disagree A Lot"
tx = pd.read_fwf("/home/PLN9630/first1k.txt", widths=widths, names=names, usecols = use_cols)

tx[np.isnan(tx)] = 0
tx.head(10)

#We have a thousand survey partcipants, which means we would expect to see each row to be sum up as one. If it's not equal to 1, 
#it's either was omitted or more than one option has been selected by a respondent.
txt1 = tx.rename(columns={u"v6677-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Agree A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
                         u"v6694-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Agree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6728-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Neither Agree Or Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP", 
            u"v6745-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Disagree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP",
            u"v6762-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP": "Disagre A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP"})

#Let's go ahead and create an extra column to tally up the sum values for each row
txt1.assign(Sum=tx.select_dtypes(['number']).sum(1) - tx["v1-ID"])
v1-ID	Agree A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Agree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Neither Agree Or Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Disagree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Disagre A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP	Sum
0	1985951	0.0	0.0	1.0	0.0	0.0	1.0
1	1985952	0.0	0.0	1.0	0.0	0.0	1.0
2	1985954	0.0	0.0	0.0	0.0	1.0	1.0
3	1985955	0.0	0.0	0.0	0.0	1.0	1.0
4	1985960	0.0	0.0	0.0	0.0	1.0	1.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	0.0	0.0	0.0	1.0	1.0
7	1985964	0.0	0.0	0.0	1.0	0.0	1.0
8	1985966	0.0	0.0	0.0	1.0	0.0	1.0
9	1985967	0.0	0.0	0.0	0.0	1.0	1.0
10	1985969	0.0	0.0	0.0	0.0	1.0	1.0
11	1985970	0.0	1.0	0.0	0.0	0.0	1.0
12	1985977	0.0	0.0	0.0	0.0	1.0	1.0
13	1985979	0.0	0.0	0.0	0.0	0.0	0.0
14	1985980	0.0	0.0	0.0	0.0	1.0	1.0
15	1985981	0.0	0.0	0.0	0.0	0.0	0.0
16	1985986	0.0	0.0	0.0	1.0	0.0	1.0
17	1985987	0.0	0.0	0.0	0.0	1.0	1.0
18	1985989	0.0	0.0	0.0	1.0	0.0	1.0
19	1985990	0.0	0.0	1.0	0.0	0.0	1.0
20	1985992	0.0	0.0	0.0	0.0	0.0	0.0
21	1985994	0.0	0.0	1.0	0.0	0.0	1.0
22	1985995	0.0	1.0	0.0	0.0	0.0	1.0
23	1985997	0.0	0.0	0.0	1.0	0.0	1.0
24	1985998	0.0	0.0	0.0	0.0	1.0	1.0
25	1986022	0.0	0.0	0.0	0.0	1.0	1.0
26	1986023	0.0	0.0	1.0	0.0	0.0	1.0
27	1986027	0.0	0.0	0.0	0.0	1.0	1.0
28	1986030	0.0	0.0	0.0	0.0	1.0	1.0
29	1986031	0.0	0.0	0.0	0.0	1.0	1.0
...	...	...	...	...	...	...	...
970	1990174	0.0	0.0	1.0	0.0	0.0	1.0
971	1990187	0.0	0.0	1.0	0.0	0.0	1.0
972	1990188	0.0	0.0	1.0	0.0	0.0	1.0
973	1990210	0.0	0.0	0.0	0.0	1.0	1.0
974	1990211	0.0	0.0	0.0	0.0	1.0	1.0
975	1990213	0.0	0.0	0.0	1.0	0.0	1.0
976	1990214	0.0	0.0	0.0	1.0	0.0	1.0
977	1990234	0.0	0.0	0.0	0.0	1.0	1.0
978	1990235	0.0	0.0	0.0	0.0	1.0	1.0
979	1990237	0.0	1.0	0.0	0.0	0.0	1.0
980	1990238	0.0	0.0	0.0	0.0	1.0	1.0
981	1990239	0.0	0.0	0.0	0.0	1.0	1.0
982	1990240	0.0	0.0	0.0	0.0	1.0	1.0
983	1990245	0.0	0.0	0.0	0.0	1.0	1.0
984	1990246	0.0	0.0	0.0	0.0	1.0	1.0
985	1990253	0.0	0.0	0.0	1.0	0.0	1.0
986	1990258	0.0	0.0	0.0	1.0	0.0	1.0
987	1990259	0.0	0.0	0.0	0.0	1.0	1.0
988	1990269	0.0	0.0	1.0	0.0	0.0	1.0
989	1990275	0.0	0.0	0.0	0.0	1.0	1.0
990	1990276	0.0	0.0	1.0	0.0	0.0	1.0
991	1990282	0.0	0.0	0.0	0.0	1.0	1.0
992	1990308	0.0	0.0	0.0	1.0	0.0	1.0
993	1990310	0.0	0.0	1.0	0.0	0.0	1.0
994	1990311	0.0	0.0	1.0	0.0	0.0	1.0
995	1990318	0.0	0.0	0.0	1.0	0.0	1.0
996	1990319	0.0	0.0	0.0	1.0	0.0	1.0
997	1990339	0.0	1.0	0.0	0.0	0.0	1.0
998	1990341	0.0	0.0	1.0	0.0	0.0	1.0
999	1990342	0.0	0.0	0.0	1.0	0.0	1.0
1000 rows × 7 columns

#As we may see, respondents were very attentive: there's only 48 instances of missed response entries,
#which represents 4.7% of all data. 
#Since it's such a negligible amount we could choose an option of dropping them as well.

#If needed, we could create an excel output for this dataframe.
tx.to_excel('tmp.xlsx')
#Let's select the next very entries for the Q#4. This will be attitudes related to traveling.
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 6 columns):
v1-ID                                                                1000 non-null int64
Agree A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP                  1000 non-null float64
Agree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP               1000 non-null float64
Neither Agree Or Disagree-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP    1000 non-null float64
Disagree A Little-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP            1000 non-null float64
Disagre A Lot-I'M 1ST OF FRNDS HAVE NEW ELCTRNC EQUIP                1000 non-null float64
dtypes: float64(5), int64(1)
memory usage: 46.9 KB
#Step1
import pandas as pd
import numpy as np
d = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")
d_short = f.iloc[6795:6851]
d_short["ID-Name"].unique()
array([u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6797-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6798-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6799-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6800-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6801-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6802-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6803-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6805-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6806-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6807-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6808-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6809-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6810-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6811-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6812-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6813-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6814-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6815-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6816-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6817-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6818-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6819-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6821-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6822-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6823-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6824-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6825-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6826-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6827-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6829-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6830-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6831-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6832-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6833-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6834-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6835-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6837-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6838-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6839-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6840-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6841-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6842-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6843-RATHER TAKE TWO/THREE SHRT QUICK VACATNS',
       u'v6844-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
       u'v6845-WHILE ON VACATION, ONLY WANT TO RELAX',
       u'v6846-VAC. SOMEWHERE DIFFERENT EVERY TIME',
       u'v6847-I LOVE THE IDEA OF TRAVELING ABROAD',
       u'v6848-WILLING MAKE TRVL PLAN WITH UNKNWN COMP',
       u'v6849-LIKE VAC. WHERE ACTV ORGNZD FOR ME',
       u'v6850-VACATION EXPRNCES DIFFERENTIATE ME/FRNDS',
       u'v6851-RATHER TAKE TWO/THREE SHRT QUICK VACATNS'], dtype=object)
#Step2
import pandas as pd

f = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")

f["Name"] = f["ID-Name"].rename()

widths = f.col_len.tolist()

names = f.Name.tolist()
#We will start with all 7 possible answers:
use_cols = [u"v1-ID",
            u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6812-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6844-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
           ]
tx = pd.read_fwf("/home/PLN9630/first1k.txt", widths=widths, names=names, usecols = use_cols)

tx[np.isnan(tx)] = 0
tx.head(10)
v1-ID	v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6812-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN	v6844-PREFER TRAVEL THE US OPPOSED TO FOREIGN
0	1985951	0.0	0.0	0.0	1.0	0.0	0.0	0.0
1	1985952	0.0	0.0	0.0	1.0	0.0	0.0	0.0
2	1985954	1.0	0.0	1.0	0.0	0.0	0.0	0.0
3	1985955	1.0	0.0	1.0	0.0	0.0	0.0	0.0
4	1985960	0.0	0.0	0.0	0.0	0.0	1.0	1.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	1.0	1.0	0.0	0.0	0.0	0.0
7	1985964	1.0	0.0	1.0	0.0	0.0	0.0	0.0
8	1985966	0.0	0.0	0.0	0.0	1.0	0.0	1.0
9	1985967	0.0	0.0	0.0	0.0	0.0	1.0	1.0
#Step3
print(tx.shape)
#(1000, 8)
#We have a thousand survey partcipants, which means we would expect to see each row to be sum up as one. If it's not equal to 1, 
#it's either was omitted or more than one option has been selected by a respondent.

#Let's rename the column titles to make it easier to understand the table.
txt = tx.rename(columns={u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN' : 'Agree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Agree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6812-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Any Agree-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Neither Agree or Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Disagree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Disagree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6844-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Any Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN'})

#As we may see, keeping such columns as Any Agree or Any Disagree creates a duplication and possible further confusion. 
#One of potential possibilities would be to drop them alltogether and leave the rest. It would be worth considering keeping
#those variables in case when we would observe missed responses. They could have been potentially used a replacement.

#Let's go ahead and create an extra column to tally up the sum values for each row
txt.assign(Sum=tx.select_dtypes(['number']).sum(1) - tx["v1-ID"])
#As we may see, respondents were very attentive: there are no duplicated answers.
(1000, 8)
v1-ID	Agree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Agree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Any Agree-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Neither Agree or Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Disagree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Disagree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Any Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Sum
0	1985951	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
1	1985952	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
2	1985954	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
3	1985955	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
4	1985960	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
7	1985964	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
8	1985966	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
9	1985967	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
10	1985969	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
11	1985970	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
12	1985977	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
13	1985979	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
14	1985980	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
15	1985981	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
16	1985986	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
17	1985987	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
18	1985989	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
19	1985990	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
20	1985992	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
21	1985994	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
22	1985995	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
23	1985997	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
24	1985998	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
25	1986022	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
26	1986023	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
27	1986027	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
28	1986030	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
29	1986031	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
...	...	...	...	...	...	...	...	...	...
970	1990174	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
971	1990187	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
972	1990188	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
973	1990210	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
974	1990211	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
975	1990213	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
976	1990214	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
977	1990234	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
978	1990235	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
979	1990237	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
980	1990238	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
981	1990239	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
982	1990240	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
983	1990245	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
984	1990246	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
985	1990253	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
986	1990258	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
987	1990259	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
988	1990269	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
989	1990275	0.0	0.0	0.0	0.0	0.0	1.0	1.0	2.0
990	1990276	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
991	1990282	1.0	0.0	1.0	0.0	0.0	0.0	0.0	2.0
992	1990308	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
993	1990310	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0
994	1990311	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
995	1990318	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
996	1990319	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
997	1990339	0.0	0.0	0.0	0.0	1.0	0.0	1.0	2.0
998	1990341	0.0	0.0	0.0	1.0	0.0	0.0	0.0	1.0
999	1990342	0.0	1.0	1.0	0.0	0.0	0.0	0.0	2.0
1000 rows × 9 columns

#Repeat Step2
#Let's update the dataset by removing "Any Disagree" and "Any Agree" values
f = pd.read_excel("/home/PLN9630/FA12_Layout.xlsx")

f["Name"] = f["ID-Name"].rename()


widths = f.col_len.tolist()

names = f.Name.tolist()

use_cols = [u"v1-ID",
            u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN']
# we selcted 5 options for the answer : "Agree A Lot", Agree A Little", "Neither Agree or Disagree", "Disagree A Little", "Disagree A Lot"
# we selcted 5 options for the answer : "Agree A Lot", Agree A Little", "Neither Agree or Disagree", "Disagree A Little", "Disagree A Lot"
tx = pd.read_fwf("/home/PLN9630/first1k.txt", widths=widths, names=names, usecols = use_cols)

tx[np.isnan(tx)] = 0
tx.head(10)

#We have a thousand survey partcipants, which means we would expect to see each row to be sum up as one. If it's not equal to 1, 
#it's either was omitted or more than one option has been selected by a respondent.
txt1 = tx.rename(columns={u'v6796-PREFER TRAVEL THE US OPPOSED TO FOREIGN' : 'Agree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6804-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Agree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6820-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Neither Agree or Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN',
            u'v6828-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Disagree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN', 
            u'v6836-PREFER TRAVEL THE US OPPOSED TO FOREIGN': 'Disagree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN'})

#Let's go ahead and create an extra column to tally up the sum values for each row
txt1.assign(Sum=tx.select_dtypes(['number']).sum(1) - tx["v1-ID"])
v1-ID	Agree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Agree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Neither Agree or Disagree-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Disagree A Little-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Disagree A Lot-PREFER TRAVEL THE US OPPOSED TO FOREIGN	Sum
0	1985951	0.0	0.0	1.0	0.0	0.0	1.0
1	1985952	0.0	0.0	1.0	0.0	0.0	1.0
2	1985954	1.0	0.0	0.0	0.0	0.0	1.0
3	1985955	1.0	0.0	0.0	0.0	0.0	1.0
4	1985960	0.0	0.0	0.0	0.0	1.0	1.0
5	1985961	0.0	0.0	0.0	0.0	0.0	0.0
6	1985963	0.0	1.0	0.0	0.0	0.0	1.0
7	1985964	1.0	0.0	0.0	0.0	0.0	1.0
8	1985966	0.0	0.0	0.0	1.0	0.0	1.0
9	1985967	0.0	0.0	0.0	0.0	1.0	1.0
10	1985969	1.0	0.0	0.0	0.0	0.0	1.0
11	1985970	0.0	1.0	0.0	0.0	0.0	1.0
12	1985977	1.0	0.0	0.0	0.0	0.0	1.0
13	1985979	0.0	0.0	0.0	0.0	0.0	0.0
14	1985980	0.0	0.0	0.0	1.0	0.0	1.0
15	1985981	0.0	0.0	0.0	0.0	1.0	1.0
16	1985986	0.0	0.0	1.0	0.0	0.0	1.0
17	1985987	0.0	0.0	1.0	0.0	0.0	1.0
18	1985989	1.0	0.0	0.0	0.0	0.0	1.0
19	1985990	1.0	0.0	0.0	0.0	0.0	1.0
20	1985992	0.0	0.0	1.0	0.0	0.0	1.0
21	1985994	0.0	0.0	1.0	0.0	0.0	1.0
22	1985995	1.0	0.0	0.0	0.0	0.0	1.0
23	1985997	0.0	0.0	0.0	0.0	0.0	0.0
24	1985998	1.0	0.0	0.0	0.0	0.0	1.0
25	1986022	0.0	0.0	0.0	0.0	0.0	0.0
26	1986023	0.0	0.0	1.0	0.0	0.0	1.0
27	1986027	1.0	0.0	0.0	0.0	0.0	1.0
28	1986030	0.0	0.0	0.0	0.0	1.0	1.0
29	1986031	1.0	0.0	0.0	0.0	0.0	1.0
...	...	...	...	...	...	...	...
970	1990174	0.0	0.0	0.0	1.0	0.0	1.0
971	1990187	0.0	0.0	1.0	0.0	0.0	1.0
972	1990188	0.0	0.0	1.0	0.0	0.0	1.0
973	1990210	0.0	0.0	0.0	0.0	1.0	1.0
974	1990211	0.0	0.0	0.0	0.0	1.0	1.0
975	1990213	1.0	0.0	0.0	0.0	0.0	1.0
976	1990214	1.0	0.0	0.0	0.0	0.0	1.0
977	1990234	1.0	0.0	0.0	0.0	0.0	1.0
978	1990235	1.0	0.0	0.0	0.0	0.0	1.0
979	1990237	0.0	0.0	0.0	1.0	0.0	1.0
980	1990238	0.0	0.0	1.0	0.0	0.0	1.0
981	1990239	1.0	0.0	0.0	0.0	0.0	1.0
982	1990240	1.0	0.0	0.0	0.0	0.0	1.0
983	1990245	0.0	0.0	0.0	1.0	0.0	1.0
984	1990246	0.0	0.0	1.0	0.0	0.0	1.0
985	1990253	0.0	0.0	1.0	0.0	0.0	1.0
986	1990258	0.0	1.0	0.0	0.0	0.0	1.0
987	1990259	0.0	0.0	1.0	0.0	0.0	1.0
988	1990269	0.0	0.0	0.0	0.0	0.0	0.0
989	1990275	0.0	0.0	0.0	0.0	1.0	1.0
990	1990276	0.0	0.0	1.0	0.0	0.0	1.0
991	1990282	1.0	0.0	0.0	0.0	0.0	1.0
992	1990308	0.0	1.0	0.0	0.0	0.0	1.0
993	1990310	0.0	0.0	0.0	0.0	0.0	0.0
994	1990311	0.0	0.0	0.0	1.0	0.0	1.0
995	1990318	0.0	1.0	0.0	0.0	0.0	1.0
996	1990319	0.0	1.0	0.0	0.0	0.0	1.0
997	1990339	0.0	0.0	0.0	1.0	0.0	1.0
998	1990341	0.0	0.0	1.0	0.0	0.0	1.0
999	1990342	0.0	1.0	0.0	0.0	0.0	1.0
1000 rows × 7 columns

#As we may see, respondents were very attentive: there's only 79 instances of missed response entries,
#which is a little less than 8% of the data overall. 
#Since it's such a negligible amount we could choose an option of dropping them as well.

#If needed, we could create an excel output for this dataframe.
tx.to_excel('tmpd.xlsx')
